{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "Before you submit this notebook, make sure everything runs as expected in the local test cases. \nPlease, paste the solution to the designed cell and do not change anything else.\n\nAlso, please, leave your first and last names below",
      "metadata": {},
      "id": "0a3f772b-9895-497f-86bc-2ad5ca5681de"
    },
    {
      "cell_type": "code",
      "source": "FirstName = \"Anna\"\nLastName = \"Markelova\"",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "62a4e020-0a8b-4cb3-a0cc-6267acdecddb"
    },
    {
      "cell_type": "code",
      "source": "from sklearn.base import BaseEstimator, ClassifierMixin\nfrom sklearn.metrics import accuracy_score\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom scipy.spatial.distance import cdist # You can use this for rbf kernel\n\nimport unittest\nimport sys\nimport io",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "537ebe13-e6bf-4c27-bbad-7aebedae907b"
    },
    {
      "cell_type": "code",
      "source": "def rbf(x_1, x_2, sigma = 1.):\n    '''Computes rbf kernel for batches of objects\n    Args:\n        x_1: torch.tensor shaped `(#samples_1, #features)` of type torch.float32\n        x_2: torch.tensor shaped `(#samples_1, #features)` of type torch.float32\n    Returns:\n        kernel function values for all pairs of samples from x_1 and x_2\n        torch.tensor of type torch.float32 shaped `(#samples_1, #samples_2)`\n    '''\n    distances = np.exp(- torch.cdist(x_1, x_2) ** 2/ (2 * sigma ** 2))\n    return torch.Tensor(distances).type(torch.float32)\n\ndef hinge_loss(scores, labels):\n    '''Mean loss for batch of objects\n    '''\n    assert len(scores.shape) == 1\n    assert len(labels.shape) == 1\n    return torch.clamp(1. - scores * labels, min = 0.).mean()\n\n\nclass SVM(BaseEstimator, ClassifierMixin):\n    @staticmethod\n    def linear(x_1, x_2):\n        '''Computes linear kernel for batches of objects\n        \n        Args:\n            x_1: torch.tensor shaped `(#samples_1, #features)` of type torch.float32\n            x_2: torch.tensor shaped `(#samples_1, #features)` of type torch.float32\n        Returns:\n            kernel function values for all pairs of samples from x_1 and x_2\n            torch.tensor shaped `(#samples_1, #samples_2)` of type torch.float32\n        '''\n        return x_1 @ x_2.T\n    \n    def __init__(\n        self,\n        lr: float = 1e-3,\n        epochs: int = 2,\n        batch_size: int = 64,\n        lmbd: float = 1e-4,\n        kernel_function = None,\n        verbose: bool = False,\n    ):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch_size = batch_size\n        self.lmbd = lmbd\n        self.kernel_function = kernel_function or SVM.linear\n        self.verbose = verbose\n        self.fitted = False\n\n    def __repr__(self):\n        return 'SVM model, fitted: {self.fitted}'\n\n    def fit(self, X, Y):\n        assert (np.abs(Y) == 1).all()\n        n_obj = len(X)\n        X, Y = torch.FloatTensor(X), torch.FloatTensor(Y)\n        K = self.kernel_function(X, X).float()\n\n        self.betas = torch.full((n_obj, 1), fill_value = 0.001, dtype = X.dtype, requires_grad = True)\n        self.bias = torch.zeros(1, requires_grad = True) # I've also add bias to the model\n        \n        optimizer = optim.SGD((self.betas, self.bias), lr = self.lr)\n        for epoch in range(self.epochs):\n            perm = torch.randperm(n_obj)  # Generate a set of random numbers of length: sample size\n            sum_loss = 0.                 # Loss for each epoch\n            for i in range(0, n_obj, self.batch_size):\n                batch_inds = perm[i: i + self.batch_size]\n                x_batch = X[batch_inds]   # Pick random samples by iterating over random permutation\n                y_batch = Y[batch_inds]   # Pick the correlating class\n                k_batch = K[batch_inds]\n                \n                optimizer.zero_grad()     # Manually zero the gradient buffers of the optimizer\n                \n                preds = k_batch @ self.betas + self.bias # get the matrix product using SVM parameters: self.betas and self.bias\n                preds = preds.flatten()\n                loss = self.lmbd * self.betas[batch_inds].T @ k_batch @ self.betas + hinge_loss(preds, y_batch)\n                loss.backward()           # Backpropagation\n                optimizer.step()          # Optimize and adjust weights\n\n                sum_loss += loss.item()   # Add the loss\n\n            if self.verbose: print(\"Epoch \" + str(epoch) + \", Loss: \" + str(sum_loss / self.batch_size))\n\n        self.X = X\n        self.fitted = True\n        return self\n\n    def predict_scores(self, batch):\n        with torch.no_grad():\n            batch = torch.from_numpy(batch).float()\n            K = self.kernel_function(batch, self.X)\n            preds = K @ self.betas + self.bias\n            # compute the margin values for every object in the batch\n            return preds.flatten()\n\n    def predict(self, batch):\n        scores = self.predict_scores(batch)\n        answers = np.full(len(batch), -1, dtype=np.int64)\n        answers[scores > 0] = 1\n        return answers",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1dfd5431f2494f8f56c119aaae6805ca",
          "grade": false,
          "grade_id": "cell-7bfbe050819ecfac",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "execution_count": null,
      "outputs": [],
      "id": "c4273801-5699-4e17-9a3d-623d47470b57"
    },
    {
      "cell_type": "markdown",
      "source": "### Test 0: Initialization (0.01 points)",
      "metadata": {},
      "id": "b78d1a9b-8569-40df-9e81-0da968cefc7a"
    },
    {
      "cell_type": "code",
      "source": "# do not change this cell\nfrom sklearn.datasets import make_circles\nX, y = make_circles(150, factor=.1, noise=.1, random_state=42)\n\n",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5f87629291b35b31fb9f91f4a61c7e28",
          "grade": true,
          "grade_id": "cell-68578dd758ce6174",
          "locked": true,
          "points": 0.01,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "execution_count": null,
      "outputs": [],
      "id": "99976677-1c44-4c70-a974-d91930bb8165"
    },
    {
      "cell_type": "markdown",
      "source": "### Test 1: SVM accuracy (0.69 points)",
      "metadata": {},
      "id": "d348d0d8-140e-407f-8934-06da0813c48f"
    },
    {
      "cell_type": "code",
      "source": "X_test, y_test = X[100:], y[100:]\nX, y = X[:100], y[:100]\ny[y==0] = -1 # for convenience with formulas\ny_test[y_test==0] = -1\nclf = SVM(epochs=150, lr=0.1, batch_size=20, verbose=False, kernel_function=rbf)\nclf.fit(X, y)\npred = clf.predict(X_test)\nassert accuracy_score(y_test, pred) > 0.95",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2e3c1fad99095246f9aab0334f14512a",
          "grade": true,
          "grade_id": "cell-1759990cd7cea5ce",
          "locked": true,
          "points": 0.69,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "execution_count": null,
      "outputs": [],
      "id": "d2d90d9b-61eb-4abd-93d0-3298d55b95d8"
    },
    {
      "cell_type": "markdown",
      "source": "### Test 2: Kernel (0.3 points)",
      "metadata": {},
      "id": "81f43183-4785-47cd-887d-aecf8ccfe445"
    },
    {
      "cell_type": "code",
      "source": "assert (np.allclose(rbf(X_kernel, X_kernel).detach().cpu().numpy(), np.array([[1.0000e+00, 2.2897e-11],[2.2897e-11, 1.0000e+00]])))",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a296d1662f5027b9b8727cd724f19ab5",
          "grade": true,
          "grade_id": "cell-a92ec82e4098bdd2",
          "locked": true,
          "points": 0.3,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "execution_count": null,
      "outputs": [],
      "id": "15370c06-9215-4460-940a-959089e662ab"
    }
  ]
}